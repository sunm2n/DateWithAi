version: '3.8'

services:
  # 공유 PostgreSQL 데이터베이스
  postgres_db:
    image: pgvector/pgvector:pg17
    container_name: datewithai-postgres
    restart: unless-stopped
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: datewithai
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./dateWithAi_backend/demo/database/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d datewithai"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datewithai-network

  # Redis (Spring 서버용)
  redis:
    image: redis:7.4-alpine
    container_name: datewithai-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ""
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datewithai-network

  # Ollama (Python AI 서버용)
  ollama:
    image: ollama/ollama:latest
    container_name: datewithai-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=1      # 병렬 처리를 1로 되돌림 (안정성 우선)
      - OLLAMA_MAX_LOADED_MODELS=2 # 1 → 2로 증가 (더 많은 모델 메모리 로드)
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_MAX_QUEUE=512       # 큐 크기 증가
      - OLLAMA_KEEP_ALIVE=5m       # 모델을 메모리에 더 오래 유지
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 12G  # 8G → 12G로 증가
          cpus: '6.0'  # 4.0 → 6.0으로 증가
        reservations:
          memory: 6G   # 4G → 6G로 증가
          cpus: '3.0'  # 2.0 → 3.0으로 증가
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - datewithai-network

# Spring과 Python 애플리케이션은 로컬에서 직접 실행
# Spring: IntelliJ에서 실행 (8080 포트)
# Python: 터미널에서 uvicorn main:app --reload (8000 포트)

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local

networks:
  datewithai-network:
    driver: bridge